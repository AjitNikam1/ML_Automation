{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Prasanthi_sample (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjitNikam1/ML_Automation/blob/master/Task1_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrOSTkc10Efm",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://shwetkm.github.io/upxlogo.png\"></img>\n",
        "\n",
        "\n",
        "# Live Project - Productionize Machine Learning models - Task 1(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZXdcFzYIU9z",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJpvRBbYIVaF",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmvR2YX0Efq",
        "colab_type": "code",
        "outputId": "6111de9d-1c48-413f-d7e3-0658b6766d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "#Import basic packages\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import time\n",
        "import pandas as pd        \n",
        "import enum\n",
        "          \n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "import plotly\n",
        "from plotly.data import iris\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split   #splitting data\n",
        "from pylab import rcParams\n",
        "from sklearn.linear_model import LinearRegression         #linear regression\n",
        "from sklearn.metrics.regression import mean_squared_error #error metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "##\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "\n",
        "#Code to import python module from classifier_sc.py file uploaded to your Google Drive\n",
        "!pip install pydrive                             # Package to use Google Drive API - not installed in Colab VM by default\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth                    # Other necessary packages\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()                         # Follow prompt in the authorization process\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "your_module = drive.CreateFile({\"id\": \"1c4uny6X2nv0kGR12zAOym1CMvoyDfyu-\"})   # \"your_module_file_id\" is the part after \"id=\" in the shareable link\n",
        "your_module.GetContentFile(\"classifier_sc.py\")          # Save the .py module file to Colab VM\n",
        "import classifier_sc  \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.11)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.4.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vu1mKFF0Efw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import dictionaries for setting basic parameters and model parameters\n",
        "from classifier_sc import classifier_config_dict,basic_params_dict,gridsearch_params_dict,MlProblemEnum,LabledDataEnum,TextDataEnum\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poDuJoLz0Ef2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Dataset\n",
        "df_iris = iris()\n",
        "# #Import Boston Housing dataset for testing Regression Problem\n",
        "# boston = datasets.load_boston()\n",
        "# # Convert the original array data into a dataframe and append the column names.\n",
        "# df_bston = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
        "# # Add a new variable in the dataframe for the target ( or label) variable\n",
        "# df_bston['House_Price'] = boston.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yeu7MGIHAOg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnaUyOay0Ef7",
        "colab_type": "code",
        "outputId": "47decdc1-5242-42f5-efaa-dbe3ed507515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#View columns and paste in classifier_sc.py file with relevant columns\n",
        "df_iris.columns\n",
        "# df_bston.columns\n",
        "df_iris.head()\n",
        "print(type(len(df_iris.index)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eGaog470EgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SpkExxK0EgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a class to perform base model operations\n",
        "class BaseModelHelper:\n",
        "    def __init__(self,base_param,base_AlgoConfigDict,base_gridsearch_params,DataFrame,base_MlProblemEnum,base_LabledDataEnum,base_TextDataEnum):\n",
        "        self.base_param = base_param\n",
        "        self.base_AlgoConfigDict = base_AlgoConfigDict\n",
        "        \n",
        "        self.base_gridsearch_params=base_gridsearch_params\n",
        "        #Initialise DataFrame\n",
        "        self.dataframe = DataFrame\n",
        "        #Initialize X\n",
        "        self.X = self.base_param['X']\n",
        "        #Initialize y\n",
        "        self.y = self.base_param['y']\n",
        "        # self.y = OutputcolumnName \n",
        "        #set random seed\n",
        "        self.random_state = self.base_param['seed']\n",
        "        #Set test_size\n",
        "        self.test_size = self.base_param['test_size']\n",
        "        self.base_MlProblemEnum = base_MlProblemEnum\n",
        "        self.base_LabledDataEnum = base_LabledDataEnum\n",
        "        self.base_TextDataEnum = base_TextDataEnum\n",
        "        self.DataFrameCount = len(DataFrame.index)\n",
        "        print('Inside BaseModelHelper')\n",
        "        #Initialise AutoML object\n",
        "        # self.AutoMLObj = AutoML(self.dataframe,self.base_MlProblemEnum,self.base_LabledDataEnum,self.base_TextDataEnum)\n",
        "        #set base model params\n",
        "        self.base_model = self.GetMlAlgoDictionary()\n",
        "        self.base_gridsearch_params=self.base_gridsearch_params\n",
        "\n",
        "        \n",
        "    #Function to Get MlAlgoDictionary on the basis of Dataset Charactristics\n",
        "    #Refered Scikit learn Algo selection Cheat Sheet - https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html \n",
        "    def GetMlAlgoDictionary(self):\n",
        "    # Initialise ML Algo Dictinary\n",
        "      MlAlgoDict = dict()\n",
        "    # Check Problem type Classifiaton\n",
        "      if self.base_MlProblemEnum is MlProblemEnum.Classification:\n",
        "        #Check if have labled data or not \n",
        "        if self.base_LabledDataEnum is LabledDataEnum.Yes:\n",
        "          #Check if Dataset samples is smaller than 100K\n",
        "          if  self.DataFrameCount < 100000:\n",
        "            MlAlgoDict.update({'LinearSVC': self.base_AlgoConfigDict['LinearSVC']})\n",
        "            if self.base_TextDataEnum is TextDataEnum.Yes:\n",
        "              MlAlgoDict.update({'KNN':self.base_AlgoConfigDict['KNN'],'SVM': self.base_AlgoConfigDict['SVM'],'RandomForestClassifier':self.base_AlgoConfigDict['RandomForestClassifier']})\n",
        "              \n",
        "      return MlAlgoDict \n",
        "     \n",
        "       #Function to standardize columns\n",
        "    def normalize_columns(self):\n",
        "        \n",
        "        # X=df_iris[self.X]\n",
        "        X=self.dataframe[self.X]\n",
        "        \n",
        "        #Scale the values\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X)\n",
        "\n",
        "        # Scale and center the data\n",
        "        fdf_normalized = scaler.transform(X)\n",
        "\n",
        "        # Create a pandas DataFrame\n",
        "        fdf_normalized = pd.DataFrame(data=fdf_normalized, index=X.index, columns=X.columns)\n",
        "        return fdf_normalized\n",
        "    \n",
        "    #Function to perform train test split\n",
        "    def train_test_split_base(self,X_norm):\n",
        "        self.X=X_norm\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X,self.dataframe[self.y],random_state=self.random_state,test_size=self.test_size)\n",
        "    \n",
        "    #GridsearchCV parameters based on the model\n",
        "          \n",
        "    def grid_params(self,model):\n",
        "        #print(model)\n",
        "        switcher={\n",
        "            'RandomForestClassifier':self.base_gridsearch_params['RandomForestClassifier'],\n",
        "            'DecisionTreeClassifier':self.base_gridsearch_params['DecisionTreeClassifier'],\n",
        "            'LogisticRegression':self.base_gridsearch_params['LogisticRegression'],\n",
        "            'SVM':self.base_gridsearch_params['SVM'],\n",
        "            'KNN':self.base_gridsearch_params['KNN'],\n",
        "            'LinearSVC':self.base_gridsearch_params['LinearSVC']\n",
        "        }\n",
        "        return switcher.get(model, \"Invalid model\")\n",
        "        \n",
        "    \n",
        "    #Building model\n",
        "    def model_build(self):\n",
        "        \n",
        "        X_norm = self.normalize_columns()\n",
        "        b.train_test_split_base(X_norm)\n",
        "        t = PrettyTable(['Name','Train Accuracy', 'Test Accuracy', 'Parameters'])\n",
        "        t.format=False\n",
        "        for key in self.base_model:\n",
        "            model=self.base_model[key]\n",
        "            model.fit(self.X_train,self.y_train)\n",
        "            y_pred_test = model.predict(self.X_test)\n",
        "           \n",
        "                      \n",
        "            #gridsearch cv\n",
        "            random_grid = self.grid_params(str(key))\n",
        "            \n",
        "            rf_gs = GridSearchCV(model, random_grid, cv = 3, n_jobs=-1, verbose=2)\n",
        "\n",
        "            rf_gs.fit(self.X_train,self.y_train)\n",
        "            y_pred_test = rf_gs.predict(self.X_test)\n",
        "            \n",
        "            train_accuracy=accuracy_score(self.y_train, rf_gs.predict(self.X_train))*100\n",
        "            test_accuracy=accuracy_score(self.y_test, y_pred_test)*100\n",
        "           # print(\"Accuracy of GridSearchCV: {}%\".format(accuracy_score(self.y_test, y_pred_test)*100))\n",
        "            t.add_row([key,train_accuracy,test_accuracy,rf_gs.best_params_])\n",
        "            #print(t)\n",
        "        return t "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "MUfvK6Bx0EgQ",
        "colab_type": "code",
        "outputId": "e049f82f-6e3e-41f2-c4a2-fe7a5f1dcd68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "# Calling BaseModelHelper with basic_params_dict and classifier_config_dict from classifier_sc.py\n",
        " \n",
        "b=BaseModelHelper(basic_params_dict,classifier_config_dict,gridsearch_params_dict,df_iris,MlProblemEnum.Classification,LabledDataEnum.Yes,TextDataEnum.Yes)\n",
        "# Model Buildingfrom sklearn.svm import SVC \n",
        "\n",
        "t= b.model_build()\n",
        "print(t)\n",
        "Html_file= open(\"output.html\",\"w\")\n",
        "Html_file.write(t.get_html_string())\n",
        "Html_file.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inside BaseModelHelper\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    2.1s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning:\n",
            "\n",
            "The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.8s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning:\n",
            "\n",
            "The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    2.3s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning:\n",
            "\n",
            "The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=-1)]: Done 1084 tasks      | elapsed:   23.2s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+------------------------+-------------------+-------------------+---------------------------------------------------------------------------------------------------------------+\n",
            "|          Name          |   Train Accuracy  |   Test Accuracy   |                                                   Parameters                                                  |\n",
            "+------------------------+-------------------+-------------------+---------------------------------------------------------------------------------------------------------------+\n",
            "|       LinearSVC        | 96.19047619047619 | 95.55555555555556 |             {'class_weight': 'balanced', 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}             |\n",
            "|          KNN           |       100.0       | 93.33333333333333 |             {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}             |\n",
            "|          SVM           | 98.09523809523809 | 95.55555555555556 |                                    {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}                                   |\n",
            "| RandomForestClassifier | 97.14285714285714 | 95.55555555555556 | {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 13} |\n",
            "+------------------------+-------------------+-------------------+---------------------------------------------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed:   35.5s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning:\n",
            "\n",
            "The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x3HmjEL0EgZ",
        "colab_type": "code",
        "outputId": "1ee075c5-06ef-4b04-a948-d548734604d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "testdict = dict()\n",
        "testdict.update({'Key1':'Value1','Key2':'Value2'})\n",
        "testdict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Key1': 'Value1', 'Key2': 'Value2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIMHHQxQ0Egd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lva8dGFY0Egh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}