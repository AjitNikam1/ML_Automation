{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Prasanthi_sample (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjitNikam1/ML_Automation/blob/master/Task1_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrOSTkc10Efm",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://shwetkm.github.io/upxlogo.png\"></img>\n",
        "\n",
        "\n",
        "# Live Project - Productionize Machine Learning models - Task 1(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZXdcFzYIU9z",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJpvRBbYIVaF",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmvR2YX0Efq",
        "colab_type": "code",
        "outputId": "d66e7d42-c963-4f75-ff2e-edaba482e51c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "#Import basic packages\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import time\n",
        "import pandas as pd        \n",
        "\n",
        "          \n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "import plotly\n",
        "from plotly.data import iris\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split   #splitting data\n",
        "from pylab import rcParams\n",
        "from sklearn.linear_model import LinearRegression         #linear regression\n",
        "from sklearn.metrics.regression import mean_squared_error #error metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "##\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "#Code to import python module from classifier_sc.py file uploaded to your Google Drive\n",
        "!pip install pydrive                             # Package to use Google Drive API - not installed in Colab VM by default\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth                    # Other necessary packages\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()                         # Follow prompt in the authorization process\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "your_module = drive.CreateFile({\"id\": \"1c4uny6X2nv0kGR12zAOym1CMvoyDfyu-\"})   # \"your_module_file_id\" is the part after \"id=\" in the shareable link\n",
        "your_module.GetContentFile(\"classifier_sc.py\")          # Save the .py module file to Colab VM\n",
        "import classifier_sc  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.11)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.12.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.4.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.7)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vu1mKFF0Efw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import dictionaries for setting basic parameters and model parameters\n",
        "from classifier_sc import classifier_config_dict,basic_params_dict,gridsearch_params_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poDuJoLz0Ef2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Dataset\n",
        "df_iris = iris()\n",
        "# #Import Boston Housing dataset for testing Regression Problem\n",
        "# boston = datasets.load_boston()\n",
        "# # Convert the original array data into a dataframe and append the column names.\n",
        "# df_bston = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
        "# # Add a new variable in the dataframe for the target ( or label) variable\n",
        "# df_bston['House_Price'] = boston.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yeu7MGIHAOg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnaUyOay0Ef7",
        "colab_type": "code",
        "outputId": "f04c3c44-ae23-400a-a2be-65de331c19ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#View columns and paste in classifier_sc.py file with relevant columns\n",
        "df_iris.columns\n",
        "# df_bston.columns\n",
        "# df_bston.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species',\n",
              "       'species_id'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eGaog470EgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SpkExxK0EgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a class to perform base model operations\n",
        "class BaseModelHelper:\n",
        "    def __init__(self,base_param,base_model,base_gridsearch_params,dataframe,OutputcolumnName):\n",
        "        self.base_param = base_param\n",
        "        self.base_model = base_model\n",
        "        self.base_gridsearch_params=base_gridsearch_params\n",
        "        self.dataframe = dataframe\n",
        "        self.OutputcolumnName = OutputcolumnName\n",
        "        self.DataFrameColNmLst =list(dataframe.columns) \n",
        "        #Initialize X\n",
        "        # self.X = self.base_param['X']\n",
        "        self.X = self.DataFrameColNmLst.remove(OutputcolumnName)\n",
        "        #Initialize y\n",
        "        # self.y = self.base_param['y']\n",
        "        self.y =list(OutputcolumnName) \n",
        "        #set random seed\n",
        "        self.random_state = self.base_param['seed']\n",
        "        #Set test_size\n",
        "        self.test_size = self.base_param['test_size']\n",
        "        #set base model params\n",
        "        self.base_model = self.base_model\n",
        "        self.base_gridsearch_params=self.base_gridsearch_params\n",
        "     \n",
        "    #Function to get List of Input columns from Dataset\n",
        "    def get_columns(self):\n",
        "      x = self.dataframe.drop([self.y],axis =1,inplace=False)\n",
        "      return x\n",
        "    #Function to standardize columns\n",
        "    def normalize_columns(self):\n",
        "        \n",
        "        # X=df_iris[self.X]\n",
        "        X=self.dataframe[self.X]\n",
        "        \n",
        "        #Scale the values\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X)\n",
        "\n",
        "        # Scale and center the data\n",
        "        fdf_normalized = scaler.transform(X)\n",
        "\n",
        "        # Create a pandas DataFrame\n",
        "        fdf_normalized = pd.DataFrame(data=fdf_normalized, index=X.index, columns=X.columns)\n",
        "        return fdf_normalized\n",
        "    \n",
        "    #Function to perform train test split\n",
        "    def train_test_split_base(self,X_norm):\n",
        "        self.X=X_norm\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X,df_iris[self.y],random_state=self.random_state,test_size=self.test_size)\n",
        "    \n",
        "    #GridsearchCV parameters based on the model\n",
        "          \n",
        "    def grid_params(self,model):\n",
        "        #print(model)\n",
        "        switcher={\n",
        "            'RandomForestClassifier':self.base_gridsearch_params['RandomForestClassifier'],\n",
        "            'DecisionTreeClassifier':self.base_gridsearch_params['DecisionTreeClassifier'],\n",
        "            'LogisticRegression':self.base_gridsearch_params['LogisticRegression'],\n",
        "            'SVM':self.base_gridsearch_params['SVM']\n",
        "        }\n",
        "        return switcher.get(model, \"Invalid model\")\n",
        "        \n",
        "    \n",
        "    #Building model\n",
        "    def model_build(self):\n",
        "        X_norm = self.normalize_columns()\n",
        "        b.train_test_split_base(X_norm)\n",
        "        t = PrettyTable(['Name','Train Accuracy', 'Test Accuracy', 'Parameters'])\n",
        "        t.format=False\n",
        "        for key in self.base_model:\n",
        "            model=self.base_model[key]\n",
        "            model.fit(self.X_train,self.y_train)\n",
        "            y_pred_test = model.predict(self.X_test)\n",
        "           \n",
        "                      \n",
        "            #gridsearch cv\n",
        "            random_grid = self.grid_params(str(key))\n",
        "            \n",
        "            rf_gs = GridSearchCV(model, random_grid, cv = 3, n_jobs=-1, verbose=2)\n",
        "\n",
        "            rf_gs.fit(self.X_train,self.y_train)\n",
        "            y_pred_test = rf_gs.predict(self.X_test)\n",
        "            \n",
        "            train_accuracy=accuracy_score(self.y_train, rf_gs.predict(self.X_train))*100\n",
        "            test_accuracy=accuracy_score(self.y_test, y_pred_test)*100\n",
        "           # print(\"Accuracy of GridSearchCV: {}%\".format(accuracy_score(self.y_test, y_pred_test)*100))\n",
        "            t.add_row([key,train_accuracy,test_accuracy,rf_gs.best_params_])\n",
        "            #print(t)\n",
        "        return t "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "MUfvK6Bx0EgQ",
        "colab_type": "code",
        "outputId": "626578fb-a630-4f5f-a958-8d0a3e2fd7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "# Calling BaseModelHelper with basic_params_dict and classifier_config_dict from classifier_sc.py \n",
        "b=BaseModelHelper(basic_params_dict,classifier_config_dict,gridsearch_params_dict,df_iris,['species_id'])\n",
        "# Model Buildingfrom sklearn.svm import SVC \n",
        "  \n",
        "t= b.model_build()\n",
        "print(t)\n",
        "Html_file= open(\"output.html\",\"w\")\n",
        "Html_file.write(t.get_html_string())\n",
        "Html_file.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-feb993c236c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBaseModelHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_params_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgridsearch_params_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_iris\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Model Buildingfrom sklearn.svm import SVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-5a62e6ca9a78>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, base_param, base_model, base_gridsearch_params, dataframe, OutputcolumnName)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#Initialize X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# self.X = self.base_param['X']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrameColNmLst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutputcolumnName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m#Initialize y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# self.y = self.base_param['y']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Index' object has no attribute 'remove'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x3HmjEL0EgZ",
        "colab_type": "code",
        "outputId": "b0d933d2-100b-4698-cde6-e62ddc8de9c3",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIMHHQxQ0Egd",
        "colab_type": "code",
        "outputId": "87ebe24b-4832-4fe4-ec81-fd3e230c0add",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lva8dGFY0Egh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}